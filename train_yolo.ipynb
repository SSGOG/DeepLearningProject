{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67befc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7cd0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_YAML_PATH = r\"D:\\VScodefiles\\DeepLearningProject\\sonar_dataset_10k_3k_3k.yaml\"\n",
    "\n",
    "# Model selection \n",
    "MODEL_NAME = \"yolo11s.pt\"  \n",
    "\n",
    "# Training parameters optimized for RTX 3060 6GB\n",
    "IMG_SIZE = 640    \n",
    "BATCH_SIZE = 16    \n",
    "EPOCHS = 100\n",
    "WORKERS = 8       \n",
    "\n",
    "# Memory optimization settings\n",
    "PRECISION = 'fp16'  \n",
    "PERSISTENT_WORKERS = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4963c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized Training Configuration ===\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU Memory: 6.4 GB\n",
      "\n",
      "=== Performance Settings ===\n",
      "Batch size: 8 (optimized for 6GB VRAM)\n",
      "Workers: 8 (increased for i7-12th gen)\n",
      "Image size: 640\n",
      "Persistent workers: True\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Optimized Training Configuration ===\")\n",
    "print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "\n",
    "print(f\"\\n=== Performance Settings ===\")\n",
    "print(f\"Batch size: {BATCH_SIZE} (optimized for 6GB VRAM)\")\n",
    "print(f\"Workers: {WORKERS} (increased for i7-12th gen)\")\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Persistent workers: {PERSISTENT_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be2f89f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model: yolo11s.pt\n",
      "Model loaded successfully: <class 'ultralytics.models.yolo.model.YOLO'>\n"
     ]
    }
   ],
   "source": [
    "# --- Load a model ---\n",
    "print(f\"\\nLoading model: {MODEL_NAME}\")\n",
    "try:\n",
    "    model = YOLO(MODEL_NAME)  # Load a pretrained model\n",
    "    print(f\"Model loaded successfully: {type(model)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model {MODEL_NAME}: {e}\")\n",
    "    # Potentially try downloading the model again or check MODEL_NAME\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd77d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset YAML structure seems valid (basic check passed).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset_info = model.model.yaml \n",
    "    print(\"Dataset YAML structure seems valid (basic check passed).\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Potential issue validating dataset structure: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415cc2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training with optimized settings...\n",
      "Ultralytics 8.3.223  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\VScodefiles\\DeepLearningProject\\sonar_dataset_10k_3k_3k.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=False, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 698.1465.5 MB/s, size: 413.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\VScodefiles\\DeepLearningProject\\sonardataset_10k_3k_3k\\train\\labels.cache... 10000 images, 6710 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10000/10000 11.6Mit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training with optimized settings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m      5\u001b[0m         data\u001b[38;5;241m=\u001b[39mDATA_YAML_PATH,\n\u001b[0;32m      6\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m      7\u001b[0m         imgsz\u001b[38;5;241m=\u001b[39mIMG_SIZE,\n\u001b[0;32m      8\u001b[0m         batch\u001b[38;5;241m=\u001b[39mBATCH_SIZE,           \n\u001b[0;32m      9\u001b[0m         workers\u001b[38;5;241m=\u001b[39mWORKERS,            \n\u001b[0;32m     10\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,                                   \n\u001b[0;32m     11\u001b[0m         patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,                \n\u001b[0;32m     12\u001b[0m         save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m         exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,              \n\u001b[0;32m     14\u001b[0m         pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,           \n\u001b[0;32m     16\u001b[0m         lr0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,                   \n\u001b[0;32m     17\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m,\n\u001b[0;32m     18\u001b[0m         warmup_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.0\u001b[39m,          \n\u001b[0;32m     19\u001b[0m         warmup_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m     20\u001b[0m         box\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7.5\u001b[39m,                    \n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,                    \n\u001b[0;32m     22\u001b[0m         dfl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m,                    \n\u001b[0;32m     23\u001b[0m         close_mosaic\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,            \n\u001b[0;32m     24\u001b[0m         overlap_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,         \n\u001b[0;32m     25\u001b[0m     )\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Save the final model path\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m--> 800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:240\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train()\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:361\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp()\n\u001b[1;32m--> 361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_train()\n\u001b[0;32m    363\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[0;32m    364\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:320\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Dataloaders\u001b[39;00m\n\u001b[0;32m    319\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mbatch_size, rank\u001b[38;5;241m=\u001b[39mLOCAL_RANK, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m )\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    326\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    327\u001b[0m     rank\u001b[38;5;241m=\u001b[39mLOCAL_RANK,\n\u001b[0;32m    328\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    329\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:102\u001b[0m, in \u001b[0;36mDetectionTrainer.get_dataloader\u001b[1;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[0;32m    100\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrect=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is incompatible with DataLoader shuffle, setting shuffle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m     shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m build_dataloader(\n\u001b[0;32m    103\u001b[0m     dataset,\n\u001b[0;32m    104\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    105\u001b[0m     workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    106\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    107\u001b[0m     rank\u001b[38;5;241m=\u001b[39mrank,\n\u001b[0;32m    108\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mcompile \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\data\\build.py:324\u001b[0m, in \u001b[0;36mbuild_dataloader\u001b[1;34m(dataset, batch, workers, shuffle, rank, drop_last, pin_memory)\u001b[0m\n\u001b[0;32m    322\u001b[0m generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\n\u001b[0;32m    323\u001b[0m generator\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m6148914691236517205\u001b[39m \u001b[38;5;241m+\u001b[39m RANK)\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InfiniteDataLoader(\n\u001b[0;32m    325\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m    326\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m    327\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle \u001b[38;5;129;01mand\u001b[39;00m sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    328\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mnw,\n\u001b[0;32m    329\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[0;32m    330\u001b[0m     prefetch_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nw \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# increase over default 2\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39mnd \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pin_memory,\n\u001b[0;32m    332\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollate_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    333\u001b[0m     worker_init_fn\u001b[38;5;241m=\u001b[39mseed_worker,\n\u001b[0;32m    334\u001b[0m     generator\u001b[38;5;241m=\u001b[39mgenerator,\n\u001b[0;32m    335\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39mdrop_last \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m%\u001b[39m batch \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    336\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\ultralytics\\data\\build.py:68\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_sampler\u001b[39m\u001b[38;5;124m\"\u001b[39m, _RepeatSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler))\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:493\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:424\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1171\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1164\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1171\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\multiprocessing\\popen_spawn_win32.py:97\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 97\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, to_child)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\K8IN\\anaconda3\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"\\nStarting training with optimized settings...\")\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=DATA_YAML_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,           \n",
    "        workers=WORKERS,            \n",
    "        device=0,                                   \n",
    "        patience=20,                \n",
    "        save=True,\n",
    "        exist_ok=True,              \n",
    "        pretrained=True,\n",
    "        optimizer='auto',           \n",
    "        lr0=0.01,                   \n",
    "        weight_decay=0.0005,\n",
    "        warmup_epochs=3.0,          \n",
    "        warmup_momentum=0.8,\n",
    "        box=7.5,                    \n",
    "        cls=0.5,                    \n",
    "        dfl=1.5,                    \n",
    "        close_mosaic=10,            \n",
    "        overlap_mask=False,         \n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"Training completed successfully!\")\n",
    "    \n",
    "    # Save the final model path\n",
    "    print(f\"Best model saved at: {model.trainer.best}\")\n",
    "    print(f\"Best model saved at: {results.save_dir / 'weights/best.pt'}\") # Or print(results) to see its attributes\n",
    "    print(f\"Training results saved in: {results.save_dir}\")\n",
    "    print(\"Check the 'results.png', 'confusion_matrix.png', 'labels.jpg', etc., in the save directory for training plots.\")\n",
    "    \n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"\\n⚠️  GPU OUT OF MEMORY ERROR!\")\n",
    "        print(\"Solutions to try:\")\n",
    "        print(\"1. Reduce batch_size to 4\")\n",
    "        print(\"2. Reduce image size to 512\")\n",
    "        print(\"3. Close other applications using GPU\")\n",
    "        print(\"4. Use 'yolo11n.pt' instead of 'yolo11s.pt'\")\n",
    "    raise e\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa8da9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model from checkpoint: D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\last.pt\n",
      "Model loaded successfully from checkpoint: <class 'ultralytics.models.yolo.model.YOLO'>\n",
      "\n",
      "Resuming training from the checkpoint...\n",
      "Ultralytics 8.3.223  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\VScodefiles\\DeepLearningProject\\sonar_dataset_10k_3k_3k.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=False, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 535.9363.3 MB/s, size: 413.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\VScodefiles\\DeepLearningProject\\sonardataset_10k_3k_3k\\train\\labels.cache... 10000 images, 6710 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10000/10000 17.2Mit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.50.1 ms, read: 289.5256.9 MB/s, size: 311.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\VScodefiles\\DeepLearningProject\\sonardataset_10k_3k_3k\\val\\labels.cache... 3000 images, 2030 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3000/3000 2.6Mit/s 0.0s0s\n",
      "Plotting labels to D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Resuming training D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\last.pt from epoch 59 to 100 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      3.98G      1.093     0.7611     0.9391         20        640: 100% ━━━━━━━━━━━━ 625/625 0.9it/s 11:58<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:270.9sss\n",
      "                   all       3000       2173       0.96      0.889      0.936      0.736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      4.01G      1.116     0.7702     0.9468          8        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:06<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:310.9sss\n",
      "                   all       3000       2173      0.965      0.882      0.938      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      4.03G      1.097     0.7644     0.9354          6        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:06<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:301.2sss\n",
      "                   all       3000       2173      0.969      0.877      0.937      0.734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      4.02G      1.093     0.7634      0.935         22        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:02<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:230.9sss\n",
      "                   all       3000       2173       0.96      0.889      0.939      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      4.03G      1.064     0.7394     0.9295         11        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 12:56<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:230.9sss\n",
      "                   all       3000       2173      0.974      0.879      0.939      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      4.01G      1.062     0.7385     0.9297         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 12:31<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:220.9sss\n",
      "                   all       3000       2173      0.969      0.885       0.94      0.752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      4.04G      1.038     0.7247     0.9251         20        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 12:29<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:230.9sss\n",
      "                   all       3000       2173      0.972      0.889      0.941      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      4.02G      1.049     0.7336     0.9223          7        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 12:36<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:230.9sss\n",
      "                   all       3000       2173      0.965      0.897      0.941       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      4.01G      1.021     0.7059     0.9195         22        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 12:34<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 0.9it/s 1:401.2sss\n",
      "                   all       3000       2173      0.973      0.895      0.943      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      4.01G      1.017     0.7058     0.9217         19        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 14:14<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:240.9sss\n",
      "                   all       3000       2173      0.966      0.899      0.945      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      4.03G      1.021     0.6995     0.9238          6        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 14:16<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:271.0sss\n",
      "                   all       3000       2173      0.968      0.895      0.947      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      4.03G      1.011      0.685     0.9193         17        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:04<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 0.9it/s 1:421.2sss\n",
      "                   all       3000       2173      0.973      0.895      0.948      0.769\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      4.03G     0.9902     0.6859     0.9105         19        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 14:13<1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 0.8it/s 1:560.9sss\n",
      "                   all       3000       2173       0.97      0.899      0.948       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      4.01G     0.9679     0.6615     0.9058         26        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 14:50<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:290.9sss\n",
      "                   all       3000       2173      0.977      0.901      0.948      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      4.04G     0.9615     0.6663     0.9063         15        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 14:31<1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:380.9sss\n",
      "                   all       3000       2173      0.984        0.9      0.948      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      4.02G      0.962     0.6618     0.9058         11        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:25<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:270.9sss\n",
      "                   all       3000       2173      0.984      0.899      0.949      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      4.01G     0.9648      0.658     0.9051         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:10<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:270.9sss\n",
      "                   all       3000       2173      0.984      0.896      0.948      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100         4G     0.9481     0.6441     0.8996         17        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:11<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:260.9sss\n",
      "                   all       3000       2173      0.982      0.899      0.948      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      4.02G     0.9301     0.6445     0.8991         18        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:05<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:260.9sss\n",
      "                   all       3000       2173      0.985      0.898      0.949       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      4.03G     0.9434     0.6272     0.9057         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:30<1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:381.0sss\n",
      "                   all       3000       2173      0.984      0.899      0.949      0.783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      4.04G     0.9174     0.6306     0.8931         23        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 13:58<1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:340.9sss\n",
      "                   all       3000       2173      0.981      0.902       0.95      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      4.04G     0.8973     0.6201     0.8871         20        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:06<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:300.8sss\n",
      "                   all       3000       2173      0.981      0.901       0.95      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      4.04G     0.8862     0.5957     0.8898         15        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:04<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.981      0.902      0.951      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      4.02G     0.9138     0.6132     0.8926         10        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:13<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.976      0.904      0.951      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      4.01G     0.8893      0.609     0.8869         15        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:16<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.976      0.908      0.951      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      4.01G     0.8888      0.606     0.8925          6        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:18<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.977      0.908      0.951      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      4.03G     0.8664     0.5858     0.8861         10        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:16<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:290.9sss\n",
      "                   all       3000       2173      0.985      0.902      0.951      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      4.04G     0.8729     0.5995     0.8842         13        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:15<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:290.9sss\n",
      "                   all       3000       2173      0.975       0.91      0.952      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      4.03G     0.8538     0.5843      0.882         15        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:18<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:290.9sss\n",
      "                   all       3000       2173      0.976      0.911      0.952      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      4.01G     0.8278     0.5657     0.8728         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:22<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:290.9sss\n",
      "                   all       3000       2173      0.977      0.911      0.952      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      4.03G     0.8371     0.5665     0.8749         17        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:15<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.985      0.905      0.953      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      4.02G     0.8305       0.56     0.8726         19        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:13<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:270.9sss\n",
      "                   all       3000       2173      0.985      0.903      0.952      0.798\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      3.99G     0.8117      0.556     0.8796          7        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:16<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:270.9sss\n",
      "                   all       3000       2173      0.986      0.904      0.952      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      4.01G     0.7987     0.5387     0.8745         15        640: 100% ━━━━━━━━━━━━ 625/625 0.7it/s 14:23<1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:290.9sss\n",
      "                   all       3000       2173      0.986      0.906      0.952      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      4.04G     0.7714     0.5312     0.8697         14        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:00<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:260.9sss\n",
      "                   all       3000       2173      0.985      0.907      0.952      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      4.02G     0.7622     0.5171     0.8664          7        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:17<1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:250.9sss\n",
      "                   all       3000       2173      0.986      0.906      0.953      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      4.04G     0.7321     0.5127     0.8604         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 12:54<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:250.9sss\n",
      "                   all       3000       2173      0.981      0.909      0.953      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      4.03G      0.753     0.5251     0.8769         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:11<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.983       0.91      0.953      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      4.03G     0.7331     0.5064     0.8589          8        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:18<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.979      0.915      0.953      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      4.03G     0.7199     0.5062     0.8552         11        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:19<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173      0.979      0.914      0.953      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      4.03G     0.7081      0.494     0.8585          8        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:19<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:280.9sss\n",
      "                   all       3000       2173       0.98      0.915      0.953      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      4.01G     0.7039     0.4884     0.8612         12        640: 100% ━━━━━━━━━━━━ 625/625 0.8it/s 13:19<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.1it/s 1:270.9sss\n",
      "                   all       3000       2173       0.98      0.914      0.953      0.804\n",
      "\n",
      "42 epochs completed in 10.377 hours.\n",
      "Optimizer stripped from D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.223  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 94/94 1.0it/s 1:300.9sss\n",
      "                   all       3000       2173      0.979      0.914      0.953      0.804\n",
      "                 MILCO        843       1420      0.977      0.891       0.94      0.778\n",
      "                 NOMBO        392        753      0.982      0.938      0.967      0.829\n",
      "Speed: 0.4ms preprocess, 27.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\u001b[0m\n",
      "Training resumed and completed successfully!\n",
      "Best model saved at: D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.pt\n",
      "Training results saved in: D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\n",
      "\n",
      "Training resumption pipeline completed!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "CHECKPOINT_PATH = r\"D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\last.pt\" # Adjust path if needed\n",
    "\n",
    "DATA_YAML_PATH = r\"D:\\VScodefiles\\DeepLearningProject\\sonar_dataset_10k_3k_3k.yaml\" # Ensure this is correct\n",
    "\n",
    "print(f\"\\nLoading model from checkpoint: {CHECKPOINT_PATH}\")\n",
    "try:\n",
    "    model = YOLO(CHECKPOINT_PATH) \n",
    "    print(f\"Model loaded successfully from checkpoint: {type(model)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model from checkpoint {CHECKPOINT_PATH}: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"\\nResuming training from the checkpoint...\")\n",
    "try:\n",
    "    results = model.train(\n",
    "        resume=True, # This tells the trainer to resume from the loaded checkpoint\n",
    "        data=DATA_YAML_PATH, # Path to your dataset YAML (should be the same as original)\n",
    "        # epochs=EPOCHS, # Optional: You can adjust the total epochs if needed, e.g., if you want to train for 100 total, set this to 100 now, and it will train for 100-58 more epochs\n",
    "        # imgsz=IMG_SIZE, # Usually not needed to specify again if saved in checkpoint, but can if changed\n",
    "        # batch=BATCH_SIZE, # Usually not needed to specify again if saved in checkpoint, but can if changed\n",
    "        # device=0, # Can specify again, or let it auto-detect\n",
    "        # ... other arguments if you need to change them from the checkpoint's original settings ...\n",
    "        # Note: Arguments like optimizer state, learning rate schedule, current epoch count are loaded from the checkpoint\n",
    "    )\n",
    "\n",
    "    print(\"Training resumed and completed successfully!\")\n",
    "\n",
    "    # The best model path is available after training finishes\n",
    "    print(f\"Best model saved at: {results.save_dir / 'weights/best.pt'}\")\n",
    "    print(f\"Training results saved in: {results.save_dir}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"\\n⚠️  GPU OUT OF MEMORY ERROR!\")\n",
    "        print(\"Solutions to try:\")\n",
    "        print(\"1. Reduce batch_size\")\n",
    "        print(\"2. Reduce image size\")\n",
    "        print(\"3. Close other applications using GPU\")\n",
    "        print(\"4. Use a smaller model\")\n",
    "    raise e\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training resumption failed with error: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"\\nTraining resumption pipeline completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15de2321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Validation ---\n",
      "Ultralytics 8.3.223  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 587.7462.3 MB/s, size: 398.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\VScodefiles\\DeepLearningProject\\sonardataset_10k_3k_3k\\val\\labels.cache... 3000 images, 2030 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3000/3000 6.4Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 188/188 5.9it/s 31.8s0.2ss\n",
      "                   all       3000       2173       0.98      0.914      0.953      0.814\n",
      "                 MILCO        843       1420      0.977      0.891       0.94      0.787\n",
      "                 NOMBO        392        753      0.984      0.938      0.967       0.84\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\VScodefiles\\DeepLearningProject\\runs\\detect\\val\u001b[0m\n",
      "Validation mAP50-95: 0.8135\n",
      "Validation mAP50: 0.9534\n"
     ]
    }
   ],
   "source": [
    "# --- Validation ---\n",
    "print(\"\\n--- Running Validation ---\")\n",
    "try:\n",
    "    # Validate the model\n",
    "    metrics = model.val()\n",
    "    print(f\"Validation mAP50-95: {metrics.box.map:.4f}\")\n",
    "    print(f\"Validation mAP50: {metrics.box.map50:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e0b4258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training history from D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\results.csv\n",
      "Loaded 42 epochs of training history.\n",
      "Available columns in results.csv:\n",
      "  [0] 'epoch'\n",
      "  [1] 'time'\n",
      "  [2] 'train/box_loss'\n",
      "  [3] 'train/cls_loss'\n",
      "  [4] 'train/dfl_loss'\n",
      "  [5] 'metrics/precision(B)'\n",
      "  [6] 'metrics/recall(B)'\n",
      "  [7] 'metrics/mAP50(B)'\n",
      "  [8] 'metrics/mAP50-95(B)'\n",
      "  [9] 'val/box_loss'\n",
      "  [10] 'val/cls_loss'\n",
      "  [11] 'val/dfl_loss'\n",
      "  [12] 'lr/pg0'\n",
      "  [13] 'lr/pg1'\n",
      "  [14] 'lr/pg2'\n",
      "\n",
      "Warning: Some expected columns not found: ['x/lr0']\n",
      "Please check the printed column list above and update the variable names in the script.\n",
      "\n",
      "Generating Training/Validation Curves...\n",
      "Saved high-quality plot: D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\custom_plots\\training_curves.png\n",
      "\n",
      "Warning: Learning Rate column (x/lr0) not found in results.csv. Plotting skipped.\n",
      "\n",
      "Generating Precision-Recall over Epochs Plot...\n",
      "Saved high-quality plot: D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\custom_plots\\precision_recall_over_epochs.png\n",
      "\n",
      "Custom high-quality plots (300 DPI) saved in: D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\custom_plots\n",
      "Remember to also check the automatically generated plots in the training and validation directories.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "TRAIN_RUN_DIR = r\"D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\" \n",
    "\n",
    "OUTPUT_PLOTS_DIR = os.path.join(TRAIN_RUN_DIR, \"custom_plots\")\n",
    "os.makedirs(OUTPUT_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "results_csv_path = os.path.join(TRAIN_RUN_DIR, \"results.csv\")\n",
    "\n",
    "if os.path.exists(results_csv_path):\n",
    "    print(f\"Loading training history from {results_csv_path}\")\n",
    "    results_df = pd.read_csv(results_csv_path)\n",
    "    print(f\"Loaded {len(results_df)} epochs of training history.\")\n",
    "    print(f\"Available columns in results.csv:\")\n",
    "    for i, col in enumerate(results_df.columns):\n",
    "        print(f\"  [{i}] '{col}'\") \n",
    "else:\n",
    "    print(f\"Warning: Could not find results.csv at {results_csv_path}. Cannot generate training curve plots.\")\n",
    "    results_df = pd.DataFrame() \n",
    "\n",
    "def save_high_quality_plot(fig, filename, dpi=300):\n",
    "    \"\"\"Saves a matplotlib figure with high DPI.\"\"\"\n",
    "    filepath = os.path.join(OUTPUT_PLOTS_DIR, filename)\n",
    "    fig.savefig(filepath, dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"Saved high-quality plot: {filepath}\")\n",
    "    plt.close(fig) \n",
    "\n",
    "# --- Generate Plots ---\n",
    "\n",
    "if not results_df.empty:\n",
    "    box_loss_col = 'train/box_loss' \n",
    "    cls_loss_col = 'train/cls_loss' \n",
    "    dfl_loss_col = 'train/dfl_loss' \n",
    "    val_box_loss_col = 'val/box_loss' \n",
    "    val_cls_loss_col = 'val/cls_loss' \n",
    "    val_dfl_loss_col = 'val/dfl_loss' \n",
    "    map50_col = 'metrics/mAP50(B)' \n",
    "    map50_95_col = 'metrics/mAP50-95(B)' \n",
    "    lr0_col = 'x/lr0' \n",
    "    precision_col = 'metrics/precision(B)' \n",
    "    recall_col = 'metrics/recall(B)' \n",
    "\n",
    "    missing_cols = []\n",
    "    for col_name in [box_loss_col, cls_loss_col, dfl_loss_col, map50_col, map50_95_col, lr0_col]:\n",
    "        if col_name not in results_df.columns:\n",
    "            missing_cols.append(col_name)\n",
    "    if missing_cols:\n",
    "        print(f\"\\nWarning: Some expected columns not found: {missing_cols}\")\n",
    "        print(\"Please check the printed column list above and update the variable names in the script.\")\n",
    "        if not any(col in results_df.columns for col in [box_loss_col, cls_loss_col, dfl_loss_col]):\n",
    "             print(\"Essential loss columns not found. Skipping loss plots.\")\n",
    "             essential_loss_found = False\n",
    "        else:\n",
    "            essential_loss_found = True\n",
    "        if not any(col in results_df.columns for col in [map50_col, map50_95_col]):\n",
    "             print(\"Essential mAP columns not found. Skipping mAP plots.\")\n",
    "             essential_mAP_found = False\n",
    "        else:\n",
    "            essential_mAP_found = True\n",
    "    else:\n",
    "        essential_loss_found = True\n",
    "        essential_mAP_found = True\n",
    "\n",
    "    if essential_loss_found or essential_mAP_found:\n",
    "        print(\"\\nGenerating Training/Validation Curves...\")\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10)) # 2x2 grid\n",
    "        fig.suptitle('YOLOv11 Training History', fontsize=16)\n",
    "\n",
    "        if box_loss_col in results_df.columns:\n",
    "            axes[0, 0].plot(results_df['epoch'], results_df[box_loss_col], label='Train Box Loss', marker='o', markersize=3)\n",
    "            if val_box_loss_col in results_df.columns:\n",
    "                 axes[0, 0].plot(results_df['epoch'], results_df[val_box_loss_col], label='Val Box Loss', marker='s', markersize=3)\n",
    "            axes[0, 0].set_title('Box Loss')\n",
    "            axes[0, 0].set_xlabel('Epoch')\n",
    "            axes[0, 0].set_ylabel('Loss')\n",
    "            axes[0, 0].grid(True, linestyle='--', alpha=0.6)\n",
    "            axes[0, 0].legend()\n",
    "        else:\n",
    "            axes[0, 0].text(0.5, 0.5, 'Box Loss Not Found', horizontalalignment='center', verticalalignment='center', transform=axes[0, 0].transAxes)\n",
    "            axes[0, 0].set_title('Box Loss (Not Available)')\n",
    "\n",
    "        if cls_loss_col in results_df.columns:\n",
    "            axes[0, 1].plot(results_df['epoch'], results_df[cls_loss_col], label='Train CLS Loss', marker='o', markersize=3, color='orange')\n",
    "            if val_cls_loss_col in results_df.columns:\n",
    "                 axes[0, 1].plot(results_df['epoch'], results_df[val_cls_loss_col], label='Val CLS Loss', marker='s', markersize=3, color='darkorange')\n",
    "            axes[0, 1].set_title('Classification Loss')\n",
    "            axes[0, 1].set_xlabel('Epoch')\n",
    "            axes[0, 1].set_ylabel('Loss')\n",
    "            axes[0, 1].grid(True, linestyle='--', alpha=0.6)\n",
    "            axes[0, 1].legend()\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'CLS Loss Not Found', horizontalalignment='center', verticalalignment='center', transform=axes[0, 1].transAxes)\n",
    "            axes[0, 1].set_title('Classification Loss (Not Available)')\n",
    "\n",
    "        if dfl_loss_col in results_df.columns:\n",
    "            axes[1, 0].plot(results_df['epoch'], results_df[dfl_loss_col], label='Train DFL Loss', marker='o', markersize=3, color='green')\n",
    "            if val_dfl_loss_col in results_df.columns:\n",
    "                 axes[1, 0].plot(results_df['epoch'], results_df[val_dfl_loss_col], label='Val DFL Loss', marker='s', markersize=3, color='darkgreen')\n",
    "            axes[1, 0].set_title('DFL Loss')\n",
    "            axes[1, 0].set_xlabel('Epoch')\n",
    "            axes[1, 0].set_ylabel('Loss')\n",
    "            axes[1, 0].grid(True, linestyle='--', alpha=0.6)\n",
    "            axes[1, 0].legend()\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'DFL Loss Not Found', horizontalalignment='center', verticalalignment='center', transform=axes[1, 0].transAxes)\n",
    "            axes[1, 0].set_title('DFL Loss (Not Available)')\n",
    "\n",
    "        if essential_mAP_found:\n",
    "            axes[1, 1].plot(results_df['epoch'], results_df[map50_col], label='mAP50', marker='o', markersize=3, color='red')\n",
    "            axes[1, 1].plot(results_df['epoch'], results_df[map50_95_col], label='mAP50-95', marker='o', markersize=3, color='purple')\n",
    "            axes[1, 1].set_title('Mean Average Precision')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].set_ylabel('mAP')\n",
    "            axes[1, 1].grid(True, linestyle='--', alpha=0.6)\n",
    "            axes[1, 1].legend()\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'mAP columns not found', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].set_title('Mean Average Precision (Not Available)')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        save_high_quality_plot(fig, \"training_curves.png\", dpi=300)\n",
    "\n",
    "\n",
    "    if lr0_col in results_df.columns:\n",
    "        print(\"\\nGenerating Learning Rate Schedule Plot...\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot(results_df['epoch'], results_df[lr0_col], label='Learning Rate (LR0)', marker='o', markersize=3, color='brown')\n",
    "        ax.set_title('Learning Rate Schedule Over Epochs')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Learning Rate')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.legend()\n",
    "        save_high_quality_plot(fig, \"learning_rate_schedule.png\", dpi=300)\n",
    "    else:\n",
    "        print(f\"\\nWarning: Learning Rate column ({lr0_col}) not found in results.csv. Plotting skipped.\")\n",
    "\n",
    "    if precision_col in results_df.columns and recall_col in results_df.columns:\n",
    "        print(\"\\nGenerating Precision-Recall over Epochs Plot...\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot(results_df['epoch'], results_df[precision_col], label='Precision', marker='o', markersize=3, color='blue')\n",
    "        ax.plot(results_df['epoch'], results_df[recall_col], label='Recall', marker='s', markersize=3, color='magenta')\n",
    "        ax.set_title('Precision and Recall over Epochs (Validation)')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.legend()\n",
    "        save_high_quality_plot(fig, \"precision_recall_over_epochs.png\", dpi=300)\n",
    "    else:\n",
    "        print(f\"\\nWarning: Precision or Recall columns ({precision_col}, {recall_col}) not found in results.csv. Plotting skipped.\")\n",
    "\n",
    "\n",
    "print(f\"\\nCustom high-quality plots (300 DPI) saved in: {OUTPUT_PLOTS_DIR}\")\n",
    "print(\"Remember to also check the automatically generated plots in the training and validation directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f54ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Export Options ---\n",
      "Ultralytics 8.3.223  Python-3.13.5 torch-2.7.1+cu118 CPU (12th Gen Intel Core(TM) i7-12700H)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.72...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.5s, saved as 'D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.onnx' (36.2 MB)\n",
      "\n",
      "Export complete (1.9s)\n",
      "Results saved to \u001b[1mD:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=D:\\VScodefiles\\DeepLearningProject\\runs\\detect\\train\\weights\\best.onnx imgsz=640 data=D:\\VScodefiles\\DeepLearningProject\\sonar_dataset_10k_3k_3k.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Model exported to ONNX format\n",
      "\n",
      "Training pipeline completed!\n"
     ]
    }
   ],
   "source": [
    "# --- Export for Deployment ---\n",
    "print(\"\\n--- Model Export Options ---\")\n",
    "export_choice = input(\"Export model to ONNX/TensorRT? (y/n): \").lower()\n",
    "if export_choice == 'y':\n",
    "    try:\n",
    "        # Export to ONNX\n",
    "        model.export(format='onnx', imgsz=IMG_SIZE)\n",
    "        print(\"Model exported to ONNX format\")\n",
    "    except Exception as e:\n",
    "        print(f\"Export failed: {e}\")\n",
    "\n",
    "print(\"\\nTraining pipeline completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
