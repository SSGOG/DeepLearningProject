{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204f3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ae6b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original images: 1170\n",
      "Target total images: 10000\n",
      "Images to be augmented: 8830\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "ORIGINAL_ROOT_PATH = Path(r\"D:\\VScodefiles\\DeepLearningProject\\RawImagesandLabels\")\n",
    "OUTPUT_DATASET_PATH = Path(r\"D:\\VScodefiles\\DeepLearningProject\\Augmented\")\n",
    "\n",
    "TARGET_TOTAL_IMAGES = 10000\n",
    "ORIGINAL_NUM_IMAGES = 1170\n",
    "AUGMENTED_NUM_IMAGES = TARGET_TOTAL_IMAGES - ORIGINAL_NUM_IMAGES\n",
    "\n",
    "print(f\"Original images: {ORIGINAL_NUM_IMAGES}\")\n",
    "print(f\"Target total images: {TARGET_TOTAL_IMAGES}\")\n",
    "print(f\"Images to be augmented: {AUGMENTED_NUM_IMAGES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5fae205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Label Format and Class Definitions ---\n",
    "CLASS_ID_TO_NAME = {0: \"MILCO\", 1: \"NOMBO\"}\n",
    "CLASS_NAME_TO_ID = {v: k for k, v in CLASS_ID_TO_NAME.items()}\n",
    "\n",
    "def parse_yolo_label_file(label_path):\n",
    "    labels = []\n",
    "    if not label_path.exists():\n",
    "        print(f\"Warning: Label file not found: {label_path} - Assuming background image.\")\n",
    "        return labels\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id, x_center, y_center, width, height = map(float, parts)\n",
    "                labels.append({\n",
    "                    'class_id': int(class_id),\n",
    "                    'x_center': x_center,\n",
    "                    'y_center': y_center,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: Malformed line in {label_path}: {line.strip()}\")\n",
    "    return labels\n",
    "\n",
    "def yolo_to_albumentations(annotations, image_width, image_height):\n",
    "    \"\"\"Convert YOLO format to normalized coordinates for Albumentations\"\"\"\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    \n",
    "    for ann in annotations:\n",
    "        x_center = ann['x_center']\n",
    "        y_center = ann['y_center']\n",
    "        width = ann['width']\n",
    "        height = ann['height']\n",
    "        \n",
    "        # Calculate normalized coordinates (already in 0-1 range)\n",
    "        x_min = x_center - width / 2\n",
    "        y_min = y_center - height / 2\n",
    "        x_max = x_center + width / 2\n",
    "        y_max = y_center + height / 2\n",
    "        \n",
    "        # Ensure coordinates are within [0,1] range\n",
    "        x_min = max(0.0, min(1.0, x_min))\n",
    "        y_min = max(0.0, min(1.0, y_min))\n",
    "        x_max = max(0.0, min(1.0, x_max))\n",
    "        y_max = max(0.0, min(1.0, y_max))\n",
    "        \n",
    "        bboxes.append([x_min, y_min, x_max, y_max])\n",
    "        class_labels.append(ann['class_id'])\n",
    "    \n",
    "    return bboxes, class_labels\n",
    "\n",
    "def albumentations_to_yolo(bboxes, class_labels, image_width, image_height):\n",
    "    \"\"\"Convert normalized coordinates back to YOLO format\"\"\"\n",
    "    yolo_annotations = []\n",
    "    \n",
    "    for bbox, label in zip(bboxes, class_labels):\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        \n",
    "        # Ensure coordinates are valid\n",
    "        x_min = max(0.0, min(1.0, x_min))\n",
    "        y_min = max(0.0, min(1.0, y_min))\n",
    "        x_max = max(0.0, min(1.0, x_max))\n",
    "        y_max = max(0.0, min(1.0, y_max))\n",
    "        \n",
    "        # Calculate YOLO format (normalized)\n",
    "        x_center = (x_min + x_max) / 2.0\n",
    "        y_center = (y_min + y_max) / 2.0\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        \n",
    "        # Ensure valid dimensions\n",
    "        width = max(0.0, min(1.0, width))\n",
    "        height = max(0.0, min(1.0, height))\n",
    "        \n",
    "        yolo_annotations.append({\n",
    "            'class_id': label,\n",
    "            'x_center': x_center,\n",
    "            'y_center': y_center,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "    \n",
    "    return yolo_annotations\n",
    "\n",
    "def analyze_class_distribution(image_label_pairs):\n",
    "    \"\"\"Analyze the distribution of classes in the dataset\"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    images_with_class = defaultdict(list)\n",
    "    \n",
    "    for idx, (img_path, label_path) in enumerate(image_label_pairs):\n",
    "        labels = parse_yolo_label_file(label_path)\n",
    "        for label in labels:\n",
    "            class_id = label['class_id']\n",
    "            class_counts[class_id] += 1\n",
    "            images_with_class[class_id].append(idx)\n",
    "    \n",
    "    # Count images with no objects (background)\n",
    "    background_images = []\n",
    "    for idx, (img_path, label_path) in enumerate(image_label_pairs):\n",
    "        labels = parse_yolo_label_file(label_path)\n",
    "        if len(labels) == 0:\n",
    "            background_images.append(idx)\n",
    "    \n",
    "    print(\"\\n--- Class Distribution Analysis ---\")\n",
    "    for class_id, count in class_counts.items():\n",
    "        class_name = CLASS_ID_TO_NAME.get(class_id, f\"Unknown_{class_id}\")\n",
    "        print(f\"Class {class_id} ({class_name}): {count} instances in {len(images_with_class[class_id])} images\")\n",
    "    \n",
    "    print(f\"Background images (no objects): {len(background_images)}\")\n",
    "    \n",
    "    return class_counts, images_with_class, background_images\n",
    "\n",
    "def calculate_augmentation_weights(class_counts, images_with_class, total_images):\n",
    "    \"\"\"Calculate how many augmentations each class needs for balancing\"\"\"\n",
    "    total_instances = sum(class_counts.values())\n",
    "    if total_instances == 0:\n",
    "        return {}\n",
    "    \n",
    "    # Calculate target instances per class (balanced)\n",
    "    num_classes = len(class_counts)\n",
    "    target_instances_per_class = total_instances * 2  # Aim for more balanced distribution\n",
    "    \n",
    "    augmentation_weights = {}\n",
    "    for class_id, count in class_counts.items():\n",
    "        shortage = max(0, target_instances_per_class - count)\n",
    "        # Weight is proportional to how underrepresented the class is\n",
    "        weight = shortage / count if count > 0 else 1.0\n",
    "        augmentation_weights[class_id] = weight\n",
    "    \n",
    "    print(\"\\n--- Augmentation Weights ---\")\n",
    "    for class_id, weight in augmentation_weights.items():\n",
    "        class_name = CLASS_ID_TO_NAME.get(class_id, f\"Unknown_{class_id}\")\n",
    "        print(f\"Class {class_id} ({class_name}): weight = {weight:.2f}\")\n",
    "    \n",
    "    return augmentation_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ac7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_pipelines():\n",
    "    \"\"\"Define multiple augmentation strategies with corrected parameters\"\"\"\n",
    "    \n",
    "    pipelines = []\n",
    "    \n",
    "    # Pipeline 0: Basic Geometric + Noise (Balanced)\n",
    "    pipelines.append(A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=15, p=0.4, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.GaussNoise(p=0.6),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "    ], bbox_params=A.BboxParams(format='albumentations', label_fields=['class_labels'])))\n",
    "\n",
    "    # Pipeline 1: Sonar-Specific Augmentations\n",
    "    pipelines.append(A.Compose([\n",
    "        A.MultiplicativeNoise(multiplier=(0.8, 1.2), p=0.5),\n",
    "        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.4),\n",
    "        A.Blur(blur_limit=3, p=0.3),\n",
    "        A.Affine(translate_percent=0.05, scale=(0.9, 1.1), rotate=(-10, 10), p=0.5),\n",
    "    ], bbox_params=A.BboxParams(format='albumentations', label_fields=['class_labels'])))\n",
    "\n",
    "    # Pipeline 2: Advanced Geometric Transformations\n",
    "    pipelines.append(A.Compose([\n",
    "        A.Rotate(limit=25, p=0.6, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.Affine(shear=(-10, 10), p=0.3),\n",
    "        A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.4),\n",
    "    ], bbox_params=A.BboxParams(format='albumentations', label_fields=['class_labels'])))\n",
    "\n",
    "    # Pipeline 3: Environmental Variations (Sonar-like)\n",
    "    pipelines.append(A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.3, p=0.7),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.4),\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.3),\n",
    "    ], bbox_params=A.BboxParams(format='albumentations', label_fields=['class_labels'])))\n",
    "    \n",
    "    return pipelines\n",
    "\n",
    "def validate_bboxes(bboxes, class_labels):\n",
    "    \"\"\"Validate and fix bounding boxes before augmentation\"\"\"\n",
    "    valid_bboxes = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    for bbox, label in zip(bboxes, class_labels):\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        \n",
    "        # Skip invalid bboxes\n",
    "        if x_min >= x_max or y_min >= y_max:\n",
    "            continue\n",
    "            \n",
    "        # Ensure coordinates are within [0,1]\n",
    "        x_min = max(0.0, min(1.0, x_min))\n",
    "        y_min = max(0.0, min(1.0, y_min))\n",
    "        x_max = max(0.0, min(1.0, x_max))\n",
    "        y_max = max(0.0, min(1.0, y_max))\n",
    "        \n",
    "        # Skip if bbox is too small after validation\n",
    "        if (x_max - x_min) < 0.01 or (y_max - y_min) < 0.01:\n",
    "            continue\n",
    "            \n",
    "        valid_bboxes.append([x_min, y_min, x_max, y_max])\n",
    "        valid_labels.append(label)\n",
    "    \n",
    "    return valid_bboxes, valid_labels\n",
    "\n",
    "def apply_mosaic_augmentation(images, labels_list, image_size=(640, 640)):\n",
    "    \"\"\"Create mosaic augmentation by combining 4 images\"\"\"\n",
    "    mosaic_img = np.zeros((image_size[0] * 2, image_size[1] * 2, 3), dtype=np.uint8)\n",
    "    mosaic_bboxes = []\n",
    "    mosaic_labels = []\n",
    "    \n",
    "    # Positions for the 4 images in the mosaic\n",
    "    positions = [\n",
    "        (0, 0),  # top-left\n",
    "        (image_size[1], 0),  # top-right\n",
    "        (0, image_size[0]),  # bottom-left\n",
    "        (image_size[1], image_size[0])  # bottom-right\n",
    "    ]\n",
    "    \n",
    "    for i, (img, labels) in enumerate(zip(images, labels_list)):\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        # Resize image to fit in mosaic quadrant\n",
    "        img_resized = cv2.resize(img, image_size)\n",
    "        x_offset, y_offset = positions[i]\n",
    "        \n",
    "        # Place image in mosaic\n",
    "        mosaic_img[y_offset:y_offset+image_size[0], x_offset:x_offset+image_size[1]] = img_resized\n",
    "        \n",
    "        # Adjust bounding boxes for mosaic position and scaling\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "        scale_x = image_size[1] / orig_w\n",
    "        scale_y = image_size[0] / orig_h\n",
    "        \n",
    "        for label in labels:\n",
    "            # Convert YOLO to pixel coordinates\n",
    "            x_center_pixel = label['x_center'] * orig_w\n",
    "            y_center_pixel = label['y_center'] * orig_h\n",
    "            width_pixel = label['width'] * orig_w\n",
    "            height_pixel = label['height'] * orig_h\n",
    "            \n",
    "            # Calculate new coordinates in mosaic\n",
    "            new_x_center = (x_center_pixel * scale_x + x_offset) / (image_size[1] * 2)\n",
    "            new_y_center = (y_center_pixel * scale_y + y_offset) / (image_size[0] * 2)\n",
    "            new_width = (width_pixel * scale_x) / (image_size[1] * 2)\n",
    "            new_height = (height_pixel * scale_y) / (image_size[0] * 2)\n",
    "            \n",
    "            # Ensure valid coordinates\n",
    "            if (0 <= new_x_center <= 1 and 0 <= new_y_center <= 1 and \n",
    "                0 < new_width <= 1 and 0 < new_height <= 1):\n",
    "                mosaic_bboxes.append({\n",
    "                    'class_id': label['class_id'],\n",
    "                    'x_center': new_x_center,\n",
    "                    'y_center': new_y_center,\n",
    "                    'width': new_width,\n",
    "                    'height': new_height\n",
    "                })\n",
    "                mosaic_labels.append(label['class_id'])\n",
    "    \n",
    "    return mosaic_img, mosaic_bboxes, mosaic_labels\n",
    "\n",
    "def apply_cutmix_augmentation(image1, labels1, image2, labels2, beta=1.0):\n",
    "    \"\"\"Apply CutMix augmentation between two images\"\"\"\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    lam = max(lam, 1 - lam)  # Ensure we use a significant portion from both\n",
    "    \n",
    "    h, w = image1.shape[:2]\n",
    "    \n",
    "    # Generate random cutting region\n",
    "    cut_ratio = np.sqrt(1 - lam)\n",
    "    cut_w = int(w * cut_ratio)\n",
    "    cut_h = int(h * cut_ratio)\n",
    "    \n",
    "    cx = np.random.randint(w)\n",
    "    cy = np.random.randint(h)\n",
    "    \n",
    "    x1 = max(0, cx - cut_w // 2)\n",
    "    y1 = max(0, cy - cut_h // 2)\n",
    "    x2 = min(w, cx + cut_w // 2)\n",
    "    y2 = min(h, cy + cut_h // 2)\n",
    "    \n",
    "    # Create mixed image\n",
    "    mixed_image = image1.copy()\n",
    "    mixed_image[y1:y2, x1:x2] = image2[y1:y2, x1:x2]\n",
    "    \n",
    "    # Combine labels (all objects from both images)\n",
    "    mixed_labels = labels1 + labels2\n",
    "    \n",
    "    return mixed_image, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ba5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "\n",
    "def load_image_and_labels(image_path, label_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Could not load image: {image_path}\")\n",
    "    height, width = image.shape[:2]\n",
    "    labels = parse_yolo_label_file(label_path)\n",
    "    return image, labels, width, height\n",
    "\n",
    "def save_yolo_annotation(annotation_list, output_label_path):\n",
    "    with open(output_label_path, 'w') as f:\n",
    "        for ann in annotation_list:\n",
    "            f.write(f\"{ann['class_id']} {ann['x_center']:.6f} {ann['y_center']:.6f} {ann['width']:.6f} {ann['height']:.6f}\\n\")\n",
    "\n",
    "def apply_augmentation_pipeline(image, bboxes, class_labels, pipeline):\n",
    "    \"\"\"Apply a specific augmentation pipeline with proper error handling.\"\"\"\n",
    "    try:\n",
    "        # Validate bboxes before augmentation\n",
    "        valid_bboxes, valid_labels = validate_bboxes(bboxes, class_labels)\n",
    "        \n",
    "        if len(valid_bboxes) == 0:\n",
    "            return image, bboxes, class_labels  # Return original if no valid bboxes\n",
    "        \n",
    "        transformed = pipeline(image=image, bboxes=valid_bboxes, class_labels=valid_labels)\n",
    "        return transformed['image'], transformed['bboxes'], transformed['class_labels']\n",
    "    except Exception as e:\n",
    "        print(f\"Augmentation error: {e}\")\n",
    "        return image, bboxes, class_labels  # Return original if augmentation fails\n",
    "\n",
    "def copy_original_file(image_path, label_path, output_images_dir, output_labels_dir):\n",
    "    output_img_path = output_images_dir / image_path.name\n",
    "    shutil.copy2(image_path, output_img_path)\n",
    "    output_lbl_path = output_labels_dir / label_path.name\n",
    "    if label_path.exists():\n",
    "        shutil.copy2(label_path, output_lbl_path)\n",
    "    else:\n",
    "        open(output_lbl_path, 'a').close()\n",
    "\n",
    "def select_images_for_class_balancing(images_with_class, augmentation_weights, num_to_select):\n",
    "    \"\"\"Select images based on class balancing weights\"\"\"\n",
    "    selected_indices = []\n",
    "    \n",
    "    for class_id, weight in augmentation_weights.items():\n",
    "        if class_id in images_with_class and len(images_with_class[class_id]) > 0:\n",
    "            num_for_class = int(num_to_select * weight)\n",
    "            available_images = images_with_class[class_id]\n",
    "            \n",
    "            # Randomly select images containing this class\n",
    "            selected = random.choices(available_images, k=min(num_for_class, len(available_images)))\n",
    "            selected_indices.extend(selected)\n",
    "    \n",
    "    # Remove duplicates and ensure we don't exceed requested number\n",
    "    selected_indices = list(set(selected_indices))\n",
    "    if len(selected_indices) > num_to_select:\n",
    "        selected_indices = random.sample(selected_indices, num_to_select)\n",
    "    \n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9876494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1170 image-label pairs.\n",
      "\n",
      "--- Class Distribution Analysis ---\n",
      "Class 0 (MILCO): 437 instances in 437 images\n",
      "Class 1 (NOMBO): 231 instances in 231 images\n",
      "Background images (no objects): 866\n",
      "\n",
      "--- Augmentation Weights ---\n",
      "Class 0 (MILCO): weight = 2.06\n",
      "Class 1 (NOMBO): weight = 4.78\n",
      "\n",
      "Using 4 augmentation pipelines.\n",
      "\n",
      "Augmentation distribution:\n",
      "  Pipeline 0: 2208 augmented images\n",
      "  Pipeline 1: 2208 augmented images\n",
      "  Pipeline 2: 2207 augmented images\n",
      "  Pipeline 3: 2207 augmented images\n",
      "\n",
      "Copying original images and labels...\n",
      "\n",
      "Starting class-balanced augmentation...\n",
      "\n",
      "Applying Pipeline 0 to generate 2208 images...\n",
      "\n",
      "Applying Pipeline 1 to generate 2208 images...\n",
      "\n",
      "Applying Pipeline 2 to generate 2207 images...\n",
      "\n",
      "Applying Pipeline 3 to generate 2207 images...\n",
      "\n",
      "Applying advanced augmentations (Mosaic, CutMix)...\n",
      "Generating 220 mosaic and 220 CutMix augmentations...\n",
      "\n",
      "--- Augmentation Complete ---\n",
      "Final dataset contains 16225 images in D:\\VScodefiles\\DeepLearningProject\\Augmented\n",
      "\n",
      "--- Class Distribution After Augmentation ---\n",
      "Class 0 (MILCO): 437 (original) + 4732 (augmented) = 5169 total\n",
      "Class 1 (NOMBO): 231 (original) + 2532 (augmented) = 2763 total\n",
      "\n",
      "IMPORTANT: Class IDs in output labels:\n",
      "  ID 0 -> MILCO\n",
      "  ID 1 -> NOMBO\n",
      "Ensure your model training configuration uses: names = ['MILCO', 'NOMBO']\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "\n",
    "def main():\n",
    "    # Collect all image-label pairs\n",
    "    all_image_label_pairs = []\n",
    "    for year_dir in ORIGINAL_ROOT_PATH.iterdir():\n",
    "        if year_dir.is_dir():\n",
    "            for img_file in year_dir.glob('*.jpg'):\n",
    "                label_file = img_file.with_suffix('.txt')\n",
    "                all_image_label_pairs.append((img_file, label_file))\n",
    "    \n",
    "    # If images are in a single folder\n",
    "    if len(all_image_label_pairs) == 0:\n",
    "        for img_file in ORIGINAL_ROOT_PATH.glob('*.jpg'):\n",
    "            label_file = img_file.with_suffix('.txt')\n",
    "            all_image_label_pairs.append((img_file, label_file))\n",
    "\n",
    "    total_found = len(all_image_label_pairs)\n",
    "    print(f\"Found {total_found} image-label pairs.\")\n",
    "\n",
    "    if total_found != ORIGINAL_NUM_IMAGES:\n",
    "        print(f\"Warning: Found {total_found} files, expected {ORIGINAL_NUM_IMAGES}.\")\n",
    "\n",
    "    if AUGMENTED_NUM_IMAGES <= 0:\n",
    "        print(\"Target number of images is less than or equal to the original number. No augmentation needed.\")\n",
    "        return\n",
    "\n",
    "    # Analyze class distribution and calculate balancing weights\n",
    "    class_counts, images_with_class, background_images = analyze_class_distribution(all_image_label_pairs)\n",
    "    augmentation_weights = calculate_augmentation_weights(class_counts, images_with_class, total_found)\n",
    "\n",
    "    # Get augmentation pipelines\n",
    "    AUGMENTATION_PIPELINES = get_augmentation_pipelines()\n",
    "    NUM_PIPELINES = len(AUGMENTATION_PIPELINES)\n",
    "    print(f\"\\nUsing {NUM_PIPELINES} augmentation pipelines.\")\n",
    "\n",
    "    # Calculate augmented images per pipeline with class balancing\n",
    "    base_aug_per_pipeline = AUGMENTED_NUM_IMAGES // NUM_PIPELINES\n",
    "    remainder_aug = AUGMENTED_NUM_IMAGES % NUM_PIPELINES\n",
    "    aug_counts_per_pipeline = [base_aug_per_pipeline] * NUM_PIPELINES\n",
    "    for i in range(remainder_aug):\n",
    "        aug_counts_per_pipeline[i] += 1\n",
    "\n",
    "    print(f\"\\nAugmentation distribution:\")\n",
    "    for i, count in enumerate(aug_counts_per_pipeline):\n",
    "        print(f\"  Pipeline {i}: {count} augmented images\")\n",
    "\n",
    "    # Create output directories\n",
    "    (OUTPUT_DATASET_PATH / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (OUTPUT_DATASET_PATH / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copy original images\n",
    "    print(\"\\nCopying original images and labels...\")\n",
    "    for img_path, lbl_path in all_image_label_pairs:\n",
    "        copy_original_file(img_path, lbl_path, OUTPUT_DATASET_PATH / \"images\", OUTPUT_DATASET_PATH / \"labels\")\n",
    "\n",
    "    # Generate augmented images with class balancing\n",
    "    print(\"\\nStarting class-balanced augmentation...\")\n",
    "    \n",
    "    # Track augmented images per class for monitoring\n",
    "    augmented_class_counts = defaultdict(int)\n",
    "    \n",
    "    for pipeline_idx in range(NUM_PIPELINES):\n",
    "        target_count = aug_counts_per_pipeline[pipeline_idx]\n",
    "        pipeline = AUGMENTATION_PIPELINES[pipeline_idx]\n",
    "        \n",
    "        print(f\"\\nApplying Pipeline {pipeline_idx} to generate {target_count} images...\")\n",
    "        \n",
    "        # Select images for this pipeline based on class balancing\n",
    "        selected_indices = select_images_for_class_balancing(\n",
    "            images_with_class, augmentation_weights, target_count\n",
    "        )\n",
    "        \n",
    "        # If we need more images, add random selection\n",
    "        if len(selected_indices) < target_count:\n",
    "            additional_needed = target_count - len(selected_indices)\n",
    "            all_indices = list(range(len(all_image_label_pairs)))\n",
    "            additional_indices = random.choices(all_indices, k=additional_needed)\n",
    "            selected_indices.extend(additional_indices)\n",
    "        \n",
    "        random.shuffle(selected_indices)\n",
    "        \n",
    "        aug_counter = 0\n",
    "        for idx in selected_indices:\n",
    "            if aug_counter >= target_count:\n",
    "                break\n",
    "                \n",
    "            img_path, lbl_path = all_image_label_pairs[idx]\n",
    "            \n",
    "            try:\n",
    "                image, labels, width, height = load_image_and_labels(img_path, lbl_path)\n",
    "                \n",
    "                # Convert to format for augmentation (normalized coordinates)\n",
    "                bboxes_norm, class_labels = yolo_to_albumentations(labels, width, height)\n",
    "                \n",
    "                # Apply augmentation\n",
    "                aug_image, aug_bboxes_norm, aug_class_labels = apply_augmentation_pipeline(\n",
    "                    image.copy(), bboxes_norm, class_labels, pipeline\n",
    "                )\n",
    "                \n",
    "                # Convert back to YOLO format\n",
    "                aug_labels_yolo = albumentations_to_yolo(aug_bboxes_norm, aug_class_labels, width, height)\n",
    "                \n",
    "                # Update class counts for monitoring\n",
    "                for label in aug_labels_yolo:\n",
    "                    augmented_class_counts[label['class_id']] += 1\n",
    "                \n",
    "                # Save augmented image and labels\n",
    "                stem = img_path.stem\n",
    "                aug_image_name = f\"{stem}_aug_p{pipeline_idx}_c{aug_counter:04d}{img_path.suffix}\"\n",
    "                aug_label_name = f\"{stem}_aug_p{pipeline_idx}_c{aug_counter:04d}.txt\"\n",
    "                \n",
    "                aug_image_path = OUTPUT_DATASET_PATH / \"images\" / aug_image_name\n",
    "                cv2.imwrite(str(aug_image_path), aug_image)\n",
    "                \n",
    "                aug_label_path = OUTPUT_DATASET_PATH / \"labels\" / aug_label_name\n",
    "                save_yolo_annotation(aug_labels_yolo, aug_label_path)\n",
    "                \n",
    "                aug_counter += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path} with Pipeline {pipeline_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Apply advanced augmentations (Mosaic and CutMix)\n",
    "    print(\"\\nApplying advanced augmentations (Mosaic, CutMix)...\")\n",
    "    \n",
    "    # Calculate how many advanced augmentations to create\n",
    "    num_advanced_aug = min(500, AUGMENTED_NUM_IMAGES // 20)  # Reduced for stability\n",
    "    \n",
    "    mosaic_count = num_advanced_aug // 2\n",
    "    cutmix_count = num_advanced_aug // 2\n",
    "    \n",
    "    print(f\"Generating {mosaic_count} mosaic and {cutmix_count} CutMix augmentations...\")\n",
    "    \n",
    "    # Mosaic Augmentation\n",
    "    successful_mosaics = 0\n",
    "    for i in range(mosaic_count):\n",
    "        try:\n",
    "            # Select 4 random images\n",
    "            selected_indices = random.sample(range(len(all_image_label_pairs)), 4)\n",
    "            images = []\n",
    "            labels_list = []\n",
    "            \n",
    "            for idx in selected_indices:\n",
    "                img_path, lbl_path = all_image_label_pairs[idx]\n",
    "                image, labels, width, height = load_image_and_labels(img_path, lbl_path)\n",
    "                images.append(image)\n",
    "                labels_list.append(labels)\n",
    "            \n",
    "            # Apply mosaic\n",
    "            mosaic_img, mosaic_labels, mosaic_class_labels = apply_mosaic_augmentation(images, labels_list)\n",
    "            \n",
    "            # Only save if we have valid objects\n",
    "            if len(mosaic_labels) > 0:\n",
    "                # Save mosaic\n",
    "                mosaic_name = f\"mosaic_{successful_mosaics:04d}.jpg\"\n",
    "                mosaic_label_name = f\"mosaic_{successful_mosaics:04d}.txt\"\n",
    "                \n",
    "                mosaic_path = OUTPUT_DATASET_PATH / \"images\" / mosaic_name\n",
    "                cv2.imwrite(str(mosaic_path), mosaic_img)\n",
    "                \n",
    "                mosaic_label_path = OUTPUT_DATASET_PATH / \"labels\" / mosaic_label_name\n",
    "                save_yolo_annotation(mosaic_labels, mosaic_label_path)\n",
    "                \n",
    "                # Update counts\n",
    "                for label in mosaic_labels:\n",
    "                    augmented_class_counts[label['class_id']] += 1\n",
    "                \n",
    "                successful_mosaics += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating mosaic {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # CutMix Augmentation\n",
    "    successful_cutmix = 0\n",
    "    for i in range(cutmix_count):\n",
    "        try:\n",
    "            # Select 2 random images\n",
    "            idx1, idx2 = random.sample(range(len(all_image_label_pairs)), 2)\n",
    "            \n",
    "            img_path1, lbl_path1 = all_image_label_pairs[idx1]\n",
    "            img_path2, lbl_path2 = all_image_label_pairs[idx2]\n",
    "            \n",
    "            image1, labels1, w1, h1 = load_image_and_labels(img_path1, lbl_path1)\n",
    "            image2, labels2, w2, h2 = load_image_and_labels(img_path2, lbl_path2)\n",
    "            \n",
    "            # Resize images to same size if different\n",
    "            if image1.shape != image2.shape:\n",
    "                image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
    "            \n",
    "            # Apply CutMix\n",
    "            cutmix_img, cutmix_labels = apply_cutmix_augmentation(image1, labels1, image2, labels2)\n",
    "            \n",
    "            # Save CutMix\n",
    "            cutmix_name = f\"cutmix_{successful_cutmix:04d}.jpg\"\n",
    "            cutmix_label_name = f\"cutmix_{successful_cutmix:04d}.txt\"\n",
    "            \n",
    "            cutmix_path = OUTPUT_DATASET_PATH / \"images\" / cutmix_name\n",
    "            cv2.imwrite(str(cutmix_path), cutmix_img)\n",
    "            \n",
    "            cutmix_label_path = OUTPUT_DATASET_PATH / \"labels\" / cutmix_label_name\n",
    "            save_yolo_annotation(cutmix_labels, cutmix_label_path)\n",
    "            \n",
    "            # Update counts\n",
    "            for label in cutmix_labels:\n",
    "                augmented_class_counts[label['class_id']] += 1\n",
    "            \n",
    "            successful_cutmix += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating CutMix {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Final statistics\n",
    "    final_count = len(list((OUTPUT_DATASET_PATH / \"images\").glob('*')))\n",
    "    print(f\"\\n--- Augmentation Complete ---\")\n",
    "    print(f\"Final dataset contains {final_count} images in {OUTPUT_DATASET_PATH}\")\n",
    "    \n",
    "    print(\"\\n--- Class Distribution After Augmentation ---\")\n",
    "    for class_id in class_counts.keys():\n",
    "        class_name = CLASS_ID_TO_NAME.get(class_id, f\"Unknown_{class_id}\")\n",
    "        original_count = class_counts[class_id]\n",
    "        augmented_count = augmented_class_counts[class_id]\n",
    "        total_count = original_count + augmented_count\n",
    "        print(f\"Class {class_id} ({class_name}): {original_count} (original) + {augmented_count} (augmented) = {total_count} total\")\n",
    "    \n",
    "    print(\"\\nIMPORTANT: Class IDs in output labels:\")\n",
    "    for class_id, class_name in CLASS_ID_TO_NAME.items():\n",
    "        print(f\"  ID {class_id} -> {class_name}\")\n",
    "    print(\"Ensure your model training configuration uses: names = ['MILCO', 'NOMBO']\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5138f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
